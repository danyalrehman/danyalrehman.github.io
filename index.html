<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Danyal Rehman, Ph.D.</title> <meta name="author" content="Danyal Rehman"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="machine learning, deep learning, scientific machine learning, portfolio"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.png"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://danyalrehman.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">Home<span class="sr-only">(current)</span></a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> Danyal Rehman, Ph.D. </h1> <p class="desc">Banting Postdoctoral Researcher @ <b>Mila – Québec AI Institute</b> / Visiting Scientist @ <b>Broad Institute of MIT &amp; Harvard</b> / Ph.D. @ <b>MIT</b></p> </header> <article> <div class="profile float-right"> <figure> <picture> <img src="/assets/img/prof_pic.jpg" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="prof_pic.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="clearfix"> <p>I’m a Banting postdoctoral researcher at <a href="https://mila.quebec/en/" rel="external nofollow noopener" target="_blank">Mila – Québec AI Institute</a> under <a href="https://en.wikipedia.org/wiki/Yoshua_Bengio" rel="external nofollow noopener" target="_blank">Yoshua Bengio</a> working on generative models for scientific discovery. I am also a visiting researcher at the <a href="https://www.broadinstitute.org/" rel="external nofollow noopener" target="_blank">Broad Institute of MIT &amp; Harvard</a> under <a href="https://en.wikipedia.org/wiki/James_J._Collins" rel="external nofollow noopener" target="_blank">Jim Collins</a> developing deep learning models for molecular discovery.</p> <p>Previously, I completed a joint Ph.D. in Mechanical Engineering and Computational Science &amp; Engineering from the <a href="https://www.mit.edu/" rel="external nofollow noopener" target="_blank">Massachusetts Institute of Technology (MIT)</a>. During that time, I was awarded fellowships from the Martin Family Society of Fellows for Sustainability and the Abdul Latif Jameel (J-WAFS) World Water and Food Systems Lab. Prior to that, I completed my undergraduate degree in Mechanical Engineering with High Honours from the <a href="https://www.utoronto.ca/" rel="external nofollow noopener" target="_blank">University of Toronto</a>.</p> <p>My Ph.D. research focused on the development of physics-informed deep learning methods and accelerated partial differential equations (PDEs) solvers for diverse physics-based applications. Examples include developing attention-enhanced neural differential equations models for ion transport phenomena (under <a href="https://en.wikipedia.org/wiki/John_H._Lienhard_V" rel="external nofollow noopener" target="_blank">John H. Lienhard</a>) and self-supervised learning (SSL) methods with Lie point symmetries for partial differential equations (under <a href="https://en.wikipedia.org/wiki/Yann_LeCun" rel="external nofollow noopener" target="_blank">Yann LeCun</a>). More recently, my interests have extended to combining deep generative models with physics-based priors for the natural sciences, with a particular focus on scientific discovery and out-of-distribution generalization.</p> <p>In my spare time, I enjoy watching/playing football (long-term supporter of <a href="https://www.arsenal.com/" rel="external nofollow noopener" target="_blank">Arsenal F.C.</a>), running, and bouldering (both indoors and outdoors).</p> <p><strong>Contact</strong>: danyal [dot] rehman [at] gmail [dot] com<br> <strong>Links</strong>: <a href="https://scholar.google.com/citations?user=XdyK1qoAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Google Scholar</a> / <a href="https://github.com/danyalrehman" rel="external nofollow noopener" target="_blank">GitHub</a> / <a href="https://www.linkedin.com/in/danyalrehman/" rel="external nofollow noopener" target="_blank">LinkedIn</a> / <a href="https://twitter.com/danyalrehman17" rel="external nofollow noopener" target="_blank">Twitter</a></p> </div> <h2><a href="/news/" style="color: inherit;">announcements</a></h2> <div class="news"> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Feb 21, 2025</th> <td> I was awarded <a href="https://banting.fellowships-bourses.gc.ca/en/home-accueil.html" rel="external nofollow noopener" target="_blank">NSERC’s Banting Postdoctoral Fellowship</a> (C$140,000) to conduct AI/ML research on material and drug discovery! </td> </tr> <tr> <th scope="row">Jul 22, 2024</th> <td> I joined <a href="https://mila.quebec/en" rel="external nofollow noopener" target="_blank">Mila – Québec Artificial Intelligence Institute</a> to work on deep learning for scientific discovery under <a href="https://en.wikipedia.org/wiki/Yoshua_Bengio" rel="external nofollow noopener" target="_blank">Yoshua Bengio</a>! </td> </tr> <tr> <th scope="row">Mar 1, 2024</th> <td> I joined the <a href="https://www.ericandwendyschmidtcenter.org/" rel="external nofollow noopener" target="_blank">Broad Institute’s Eric and Wendy Schmidt Center</a> to work on generative models for drug discovery under <a href="https://en.wikipedia.org/wiki/James_J._Collins" rel="external nofollow noopener" target="_blank">Jim Collins</a>! </td> </tr> <tr> <th scope="row">Dec 21, 2023</th> <td> I successfully defended my Ph.D. from <a href="https://web.mit.edu" rel="external nofollow noopener" target="_blank">MIT</a>! </td> </tr> <tr> <th scope="row">Jun 5, 2023</th> <td> I started an AI/ML Fellowship at <a href="https://www.flagshippioneering.com/" rel="external nofollow noopener" target="_blank">Flagship Pioneering</a>! #AI4Science </td> </tr> <tr> <th scope="row">Sep 1, 2022</th> <td> I was awarded a <a href="https://martin-fellows.mit.edu/" rel="external nofollow noopener" target="_blank">Martin Sustainability Fellowship</a> ($100,000) for my research in AI for Science! </td> </tr> </table> </div> </div> <h2><a href="/publications/" style="color: inherit;">selected publications</a></h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Preprint</abbr></div> <div id="REHMAN2025FORT" class="col-sm-8"> <div class="title">FORT: Forward-only regression training of normalizing flows</div> <div class="author"> <em>Danyal Rehman</em>, Oscar Davis, Jiarui Lu, Jian Tang, Michael Bronstein, Yoshua Bengio, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Alexander Tong, Avishek Joey Bose' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '1'); ">2 more authors</span> </div> <div class="periodical"> <em>arXiv preprint arXiv:2506.01158</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2506.01158" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://arxiv.org/pdf/2506.01158" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Simulation-free training frameworks have been at the forefront of the generative modeling revolution in continuous spaces, leading to neural dynamical systems that encompass modern large-scale diffusion and flow-matching models. Despite the scalability of training, the generation of high-quality samples and their corresponding likelihood under the model requires expensive numerical simulation—inhibiting adoption in numerous scientific applications such as equilibrium sampling of molecular systems. In this paper, we revisit classical normalizing flows as one-step generative models with exact likelihoods and propose a novel, scalable training objective that does not require computing the expensive change of variable formula used in conventional maximum likelihood training. We propose Forward-Only Regression Training (FORT), a simple regression objective that maps prior samples under our flow to specifically chosen targets. We demonstrate that FORT supports a wide class of targets, such as optimal transport targets and targets from pre-trained continuous-time normalizing flows (CNF). We further demonstrate that by using CNF targets, our one-step flows allow for larger-scale training that exceeds the performance and stability of maximum likelihood training, while unlocking a broader class of architectures that were previously challenging to train. Empirically, we elucidate that our trained flows can perform equilibrium conformation sampling in Cartesian coordinates of alanine dipeptide, alanine tripeptide, and alanine tetrapeptide.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">REHMAN2025FORT</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{FORT: Forward-only regression training of normalizing flows}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Rehman, Danyal and Davis, Oscar and Lu, Jiarui and Tang, Jian and Bronstein, Michael and Bengio, Yoshua and Tong, Alexander and Bose, Avishek Joey}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2506.01158}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Normalizing Flows, Generative Models, Optimal Transport, Flow Matching, AI for Science}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#4C96B6"><a href="https://www.sciencedirect.com/journal/chemical-engineering-journal" rel="external nofollow noopener" target="_blank">CEJ</a></abbr></div> <div id="REHMAN2024149806" class="col-sm-8"> <div class="title">Physics-informed deep learning for multi-species membrane separations</div> <div class="author"> <em>Danyal Rehman</em>, and John H. Lienhard</div> <div class="periodical"> <em>Chemical Engineering Journal</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1016/j.cej.2024.149806" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="https://doi.org/10.1016/j.cej.2024.149806"></span> <span class="__dimensions_badge_embed__" data-doi="https://doi.org/10.1016/j.cej.2024.149806" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Conventional continuum models for ion transport across polyamide membranes require solving partial differential equations (PDEs). These models typically introduce a host of assumptions and simplifications to improve the computational tractability of existing solvers. As a consequence of these constraints, conventional models struggle to generalize predictive performance to new unseen conditions. Deep learning has recently shown promise in alleviating many of these concerns, making it a promising avenue for surrogate models that can replace conventional PDE-based approaches. In this work, we develop a physics-informed deep learning model to predict ion transport across polyamide membranes. The proposed architecture leverages neural differential equations in conjunction with classical closure models as inductive biases directly encoded into the neural framework. The neural methods are pre-trained on simulated data from continuum models and fine-tuned on independent experiments to learn multi-ionic rejection behaviour. We also harness the attention mechanism, commonly observed in language modelling, to learn and infer key ion-pairing relationships. Gaussian noise augmentations from experimental uncertainty estimates are also introduced into the measured data to improve robustness and generalization. We study the neural framework’s performance relative to conventional PDE-based methods, and also compare the use of hard/soft inductive bias constraints on prediction accuracy. Lastly, we compare our approach to other competitive deep learning architectures and illustrate strong agreement with experimental measurements across all studied datasets.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">REHMAN2024149806</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Physics-informed deep learning for multi-species membrane separations}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Rehman, Danyal and Lienhard, John H.}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Chemical Engineering Journal}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{149806}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.cej.2024.149806}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1385-8947}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Ion selectivity, Membrane separations, Physics-informed machine learning, Scientific machine learning, Deep learning}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#634488"><a href="https://nips.cc/" rel="external nofollow noopener" target="_blank">NeurIPS</a></abbr></div> <div id="GARRIDO2023SELFSUPERVISED" class="col-sm-8"> <div class="title">Self-supervised learning with Lie symmetries for partial differential equations</div> <div class="author"> Grégoire Mialon, Quentin Garrido, Hannah Lawrence, <em>Danyal Rehman</em>, Yann LeCun, and Bobak T. Kiani</div> <div class="periodical"> <em>Advances in Neural Information Processing Systems (NeurIPS)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2307.05432" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://arxiv.org/pdf/2307.05432" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://www.dropbox.com/s/9bpzbp2ioyx2w0u/iclr23_ssl.pdf?dl=0" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Poster</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Machine learning for differential equations paves the way for computationally efficient alternatives to numerical solvers, with potentially broad impacts in science and engineering. Though current algorithms typically require simulated training data tailored to a given setting, one may instead wish to learn useful information from heterogeneous sources, or from real dynamical systems observations that are messy or incomplete. In this work, we learn general-purpose representations of PDEs from heterogeneous data by implementing joint embedding methods for self-supervised learning (SSL), a framework for unsupervised representation learning that has had notable success in computer vision. Our representation outperforms baseline approaches to invariant tasks, such as regressing the coefficients of a PDE, while also improving the time-stepping performance of neural solvers. We hope that our proposed methodology will prove useful in the eventual development of general-purpose foundation models for PDEs.</p> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Danyal Rehman. Last updated: June 09, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script defer src="/assets/js/copy_code.js" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>